A hardware-integrated AI simulation system designed to optimize urban traffic flow using Reinforcement Learning (Q-Learning), computer vision, and IoT, reducing average commute time by dynamically controlling signal timings.

âœ¨ Highlights

Â· ğŸ¤– AI-Powered: Uses a Q-Learning RL model to make intelligent traffic signal decisions.
Â· ğŸ¯ Simulation & Real-World Bridge: Connects the SUMO traffic simulator to physical hardware (ESP32/Arduino).
Â· ğŸ‘ï¸ Computer Vision: Includes live camera feed detection for real-time vehicle counting.
Â· ğŸ”§ Hardware Integration: Controls RGB LED traffic lights and 7-segment displays based on simulation data.
Â· ğŸ“Š Data-Driven: Analyzes traffic patterns to predict and mitigate congestion bottlenecks.

ğŸ“ Repository Structure

â”œâ”€â”€ ğŸ“„ RL_MODEL.py                 # Reinforcement Learning (Q-Learning) model training and inference
â”œâ”€â”€ ğŸ“„ SUMO_TO_ARDUINO.ipynb       # Jupyter Notebook: Main bridge between SUMO sim and Arduino
â”œâ”€â”€ ğŸ“„ Arduino.ino                 # Code for ESP32/Arduino to control LEDs & display
â”œâ”€â”€ ğŸ“ Camera-detection/           # OpenCV scripts for real-time vehicle detection

âš™ï¸ How It Works

1. Simulation (SUMO)

The SUMO simulator generates realistic urban traffic scenarios. Data like vehicle count, speed, and queue length are extracted in real-time using the TraCI API.

2. AI Decision Making (RL Model)

The RL_MODEL.py implements a Q-Learning algorithm. It takes the live traffic data from SUMO, predicts potential congestion, and decides the optimal signal timing (Green/Red light duration) to minimize overall wait time.

3. Hardware Control (Arduino/ESP32)

The decision from the AI model is sent via serial communication to the microcontroller (Arduino.ino), which controls:

Â· ğŸš¦ RGB LEDs acting as traffic signals.
Â· â° 7-Segment Displays showing countdown timers.

4.  Real-Time Camera Feed

The Camera-detection module uses OpenCV and Haar Cascades to count vehicles from a live camera feed, which can be used as an alternative input to the AI model.


ğŸš€ Getting Started

Prerequisites

Â· Python 3.8+
Â· Arduino IDE
Â· SUMO (Simulation of Urban Mobility)
Â· An ESP32 or Arduino Board
Â· RGB LEDs, 7-Segment Displays, Resistors

Installation & Setup

1. Clone the repo
   ```bash
   git clone https://github.com/SanyaSingh0001/TrafficSystem
   cd TrafficSystem
   ```
2. Install Python dependencies
   ```bash
   pip install -r requirements.txt
   # Main libraries: traci, numpy, opencv-python, pyserial, pandas
   ```
3. Set up SUMO
   Â· Download and install SUMO from here.
   Â· Ensure the SUMO_HOME environment variable is set.
4. Upload the Arduino Code
   Â· Open Arduino.ino in the Arduino IDE.
   Â· Select your board  and port.
   Â· Upload the code.
5. Run the System
   Â· Run the Jupyter Notebook SUMO_TO_ARDUINO.ipynb cell by cell.
   Â· Alternatively, run the Python scripts:
     ```bash
     python RL_MODEL.py


ğŸ§  The AI Model: Reinforcement Learning

Our Q-Learning model is trained to maximize the reward function, which is based on:

Â· Negative reward for vehicles waiting at a red light.
Â· Positive reward for vehicles passing through a green light.
Â· High penalty for emergency vehicles being stuck.

The state includes the number of vehicles on each lane, and the actions are which signal to turn green.


ğŸ¯ Future Implementations

Â· Implement DQN (Deep Q-Network) for more complex intersections.
Â· Integrate V2X (Vehicle-to-Everything) communication.
Â· Develop a web dashboard for real-time monitoring.
Â· Use GPS data for city-wide traffic prediction.


<div align="center">

Built with passion for Smart India Hackathon (SIH)

âš¡ Innovation | ğŸ¤– Automation | ğŸš€ Technology

</div>
     
